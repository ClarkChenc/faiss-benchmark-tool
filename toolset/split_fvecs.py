#!/usr/bin/env python3
"""
.fvecs æ•°æ®åˆ†å‰²å·¥å…·

å°†å¤§å‹ .fvecs æ–‡ä»¶åˆ†å‰²æˆæŒ‡å®šå¤§å°çš„å¤šä¸ªå°æ–‡ä»¶ï¼Œæ”¯æŒå†…å­˜ä¼˜åŒ–çš„æµå¼å¤„ç†ã€‚
é€‚ç”¨äºå¤„ç†å¤§è§„æ¨¡å‘é‡æ•°æ®é›†ï¼Œé¿å…å†…å­˜æº¢å‡ºé—®é¢˜ã€‚
"""

import argparse
import os
import math
import numpy as np
from tqdm import tqdm
from ../faiss_benchmark.utils import (
    get_fvecs_info, fvecs_read_range, fvecs_write_streaming
)


def split_fvecs_file(input_file, output_dir, chunk_size, output_prefix=None, start_index=0):
    """
    å°† .fvecs æ–‡ä»¶åˆ†å‰²æˆæŒ‡å®šå¤§å°çš„å¤šä¸ªæ–‡ä»¶
    
    Args:
        input_file: è¾“å…¥çš„ .fvecs æ–‡ä»¶è·¯å¾„
        output_dir: è¾“å‡ºç›®å½•
        chunk_size: æ¯ä¸ªåˆ†å‰²æ–‡ä»¶çš„å‘é‡æ•°é‡
        output_prefix: è¾“å‡ºæ–‡ä»¶åå‰ç¼€ï¼ˆé»˜è®¤ä½¿ç”¨è¾“å…¥æ–‡ä»¶åï¼‰
        start_index: èµ·å§‹ç´¢å¼•ï¼ˆé»˜è®¤ä»0å¼€å§‹ï¼‰
    
    Returns:
        list: ç”Ÿæˆçš„æ–‡ä»¶è·¯å¾„åˆ—è¡¨
    """
    print(f"ğŸ” æ­£åœ¨åˆ†æè¾“å…¥æ–‡ä»¶: {input_file}")
    
    # è·å–æ–‡ä»¶ä¿¡æ¯
    total_vectors, dimension = get_fvecs_info(input_file)
    
    print(f"ğŸ“Š æ–‡ä»¶ä¿¡æ¯:")
    print(f"  æ€»å‘é‡æ•°: {total_vectors:,}")
    print(f"  å‘é‡ç»´åº¦: {dimension}")
    print(f"  æ–‡ä»¶å¤§å°: {os.path.getsize(input_file) / (1024**3):.2f} GB")
    
    # è®¡ç®—åˆ†å‰²å‚æ•°
    if start_index >= total_vectors:
        raise ValueError(f"èµ·å§‹ç´¢å¼• {start_index} è¶…å‡ºæ–‡ä»¶èŒƒå›´ (0-{total_vectors-1})")
    
    available_vectors = total_vectors - start_index
    num_chunks = math.ceil(available_vectors / chunk_size)
    
    print(f"ğŸ“¦ åˆ†å‰²è®¡åˆ’:")
    print(f"  èµ·å§‹ç´¢å¼•: {start_index}")
    print(f"  å¯ç”¨å‘é‡: {available_vectors:,}")
    print(f"  æ¯å—å¤§å°: {chunk_size:,}")
    print(f"  åˆ†å‰²å—æ•°: {num_chunks}")
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(output_dir, exist_ok=True)
    
    # ç¡®å®šè¾“å‡ºæ–‡ä»¶å‰ç¼€
    if output_prefix is None:
        output_prefix = os.path.splitext(os.path.basename(input_file))[0]
    
    # åˆ†å‰²æ–‡ä»¶
    output_files = []
    current_index = start_index
    
    print(f"ğŸš€ å¼€å§‹åˆ†å‰²...")
    
    for chunk_idx in tqdm(range(num_chunks), desc="åˆ†å‰²è¿›åº¦"):
        # è®¡ç®—å½“å‰å—çš„å¤§å°
        remaining_vectors = available_vectors - (chunk_idx * chunk_size)
        current_chunk_size = min(chunk_size, remaining_vectors)
        
        # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å
        output_filename = f"{output_prefix}_part_{chunk_idx+1:04d}.fvecs"
        output_path = os.path.join(output_dir, output_filename)
        
        # åˆ›å»ºå‘é‡ç”Ÿæˆå™¨
        def vector_generator():
            # ä½¿ç”¨è¾ƒå°çš„æ‰¹æ¬¡è¯»å–ï¼Œé¿å…å†…å­˜é—®é¢˜
            batch_size = min(50000, current_chunk_size)
            read_index = current_index
            remaining = current_chunk_size
            
            while remaining > 0:
                actual_batch_size = min(batch_size, remaining)
                vectors = fvecs_read_range(input_file, read_index, actual_batch_size)
                yield vectors
                
                read_index += actual_batch_size
                remaining -= actual_batch_size
        
        # å†™å…¥æ–‡ä»¶
        fvecs_write_streaming(output_path, vector_generator(), current_chunk_size)
        
        output_files.append(output_path)
        current_index += current_chunk_size
        
        # æ˜¾ç¤ºå½“å‰å—ä¿¡æ¯
        tqdm.write(f"  âœ… ç”Ÿæˆ: {output_filename} ({current_chunk_size:,} å‘é‡)")
    
    print(f"ğŸ‰ åˆ†å‰²å®Œæˆ!")
    print(f"  ç”Ÿæˆæ–‡ä»¶æ•°: {len(output_files)}")
    print(f"  è¾“å‡ºç›®å½•: {output_dir}")
    
    # éªŒè¯åˆ†å‰²ç»“æœ
    print(f"ğŸ” éªŒè¯åˆ†å‰²ç»“æœ...")
    total_output_vectors = 0
    
    for i, output_file in enumerate(output_files):
        vectors, dim = get_fvecs_info(output_file)
        total_output_vectors += vectors
        
        if dim != dimension:
            print(f"  âš ï¸ è­¦å‘Š: {output_file} ç»´åº¦ä¸åŒ¹é… ({dim} vs {dimension})")
        
        print(f"  ğŸ“„ {os.path.basename(output_file)}: {vectors:,} å‘é‡")
    
    if total_output_vectors == available_vectors:
        print(f"  âœ… éªŒè¯é€šè¿‡: æ€»å‘é‡æ•°åŒ¹é… ({total_output_vectors:,})")
    else:
        print(f"  âŒ éªŒè¯å¤±è´¥: å‘é‡æ•°ä¸åŒ¹é… ({total_output_vectors:,} vs {available_vectors:,})")
    
    return output_files


def estimate_memory_usage(total_vectors, dimension, chunk_size):
    """
    ä¼°ç®—å†…å­˜ä½¿ç”¨é‡
    
    Args:
        total_vectors: æ€»å‘é‡æ•°
        dimension: å‘é‡ç»´åº¦
        chunk_size: åˆ†å‰²å¤§å°
    
    Returns:
        dict: å†…å­˜ä½¿ç”¨ä¼°ç®—ä¿¡æ¯
    """
    # æ¯ä¸ªå‘é‡çš„å­—èŠ‚æ•° (float32)
    bytes_per_vector = dimension * 4
    
    # å•ä¸ªåˆ†å‰²æ–‡ä»¶çš„å†…å­˜éœ€æ±‚
    chunk_memory_mb = (chunk_size * bytes_per_vector) / (1024 * 1024)
    
    # è¯»å–ç¼“å†²åŒºå†…å­˜ (å‡è®¾50kå‘é‡çš„æ‰¹æ¬¡)
    buffer_size = min(50000, chunk_size)
    buffer_memory_mb = (buffer_size * bytes_per_vector) / (1024 * 1024)
    
    # æ€»å†…å­˜ä¼°ç®— (åŒ…æ‹¬ä¸€äº›å¼€é”€)
    total_memory_mb = chunk_memory_mb + buffer_memory_mb + 100  # 100MB å¼€é”€
    
    return {
        'chunk_memory_mb': chunk_memory_mb,
        'buffer_memory_mb': buffer_memory_mb,
        'total_memory_mb': total_memory_mb,
        'chunk_memory_gb': chunk_memory_mb / 1024,
        'total_memory_gb': total_memory_mb / 1024
    }


def suggest_chunk_size(total_vectors, dimension, max_memory_gb=4.0):
    """
    æ ¹æ®å†…å­˜é™åˆ¶å»ºè®®åˆé€‚çš„åˆ†å‰²å¤§å°
    
    Args:
        total_vectors: æ€»å‘é‡æ•°
        dimension: å‘é‡ç»´åº¦
        max_memory_gb: æœ€å¤§å†…å­˜é™åˆ¶ (GB)
    
    Returns:
        int: å»ºè®®çš„åˆ†å‰²å¤§å°
    """
    bytes_per_vector = dimension * 4
    max_memory_bytes = max_memory_gb * 1024 * 1024 * 1024
    
    # é¢„ç•™ä¸€äº›å†…å­˜ç»™ç¼“å†²åŒºå’Œå¼€é”€
    available_memory_bytes = max_memory_bytes * 0.8
    
    suggested_chunk_size = int(available_memory_bytes / bytes_per_vector)
    
    # ç¡®ä¿ä¸è¶…è¿‡æ€»å‘é‡æ•°
    suggested_chunk_size = min(suggested_chunk_size, total_vectors)
    
    # ç¡®ä¿è‡³å°‘æœ‰1000ä¸ªå‘é‡
    suggested_chunk_size = max(suggested_chunk_size, 1000)
    
    return suggested_chunk_size


def main():
    parser = argparse.ArgumentParser(
        description=".fvecs æ•°æ®åˆ†å‰²å·¥å…· - å°†å¤§å‹å‘é‡æ–‡ä»¶åˆ†å‰²æˆæŒ‡å®šå¤§å°çš„å¤šä¸ªæ–‡ä»¶",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹ç”¨æ³•:
  # åŸºæœ¬åˆ†å‰²ï¼šå°†æ–‡ä»¶åˆ†å‰²æˆæ¯ä¸ª100ä¸‡å‘é‡çš„å—
  python split_fvecs.py -i data/large.fvecs -o data/splits -s 1000000
  
  # è‡ªå®šä¹‰è¾“å‡ºå‰ç¼€
  python split_fvecs.py -i data/sift.fvecs -o data/splits -s 500000 -p sift_split
  
  # ä»æŒ‡å®šä½ç½®å¼€å§‹åˆ†å‰²
  python split_fvecs.py -i data/large.fvecs -o data/splits -s 1000000 --start 2000000
  
  # æ ¹æ®å†…å­˜é™åˆ¶è‡ªåŠ¨å»ºè®®åˆ†å‰²å¤§å°
  python split_fvecs.py -i data/large.fvecs -o data/splits --suggest-size --memory 8
  
  # ä»…æ˜¾ç¤ºæ–‡ä»¶ä¿¡æ¯ï¼Œä¸è¿›è¡Œåˆ†å‰²
  python split_fvecs.py -i data/large.fvecs --info-only
        """,
    )
    
    parser.add_argument("-i", "--input", required=True, 
                       help="è¾“å…¥çš„ .fvecs æ–‡ä»¶è·¯å¾„")
    parser.add_argument("-o", "--output", 
                       help="è¾“å‡ºç›®å½•è·¯å¾„")
    parser.add_argument("-s", "--size", type=int,
                       help="æ¯ä¸ªåˆ†å‰²æ–‡ä»¶çš„å‘é‡æ•°é‡")
    parser.add_argument("-p", "--prefix", 
                       help="è¾“å‡ºæ–‡ä»¶åå‰ç¼€ï¼ˆé»˜è®¤ä½¿ç”¨è¾“å…¥æ–‡ä»¶åï¼‰")
    parser.add_argument("--start", type=int, default=0,
                       help="èµ·å§‹å‘é‡ç´¢å¼•ï¼ˆé»˜è®¤: 0ï¼‰")
    parser.add_argument("--suggest-size", action="store_true",
                       help="æ ¹æ®å†…å­˜é™åˆ¶å»ºè®®åˆ†å‰²å¤§å°")
    parser.add_argument("--memory", type=float, default=4.0,
                       help="å†…å­˜é™åˆ¶ (GBï¼Œç”¨äºå»ºè®®åˆ†å‰²å¤§å°ï¼Œé»˜è®¤: 4.0)")
    parser.add_argument("--info-only", action="store_true",
                       help="ä»…æ˜¾ç¤ºæ–‡ä»¶ä¿¡æ¯ï¼Œä¸è¿›è¡Œåˆ†å‰²")
    
    args = parser.parse_args()
    
    # æ£€æŸ¥è¾“å…¥æ–‡ä»¶
    if not os.path.exists(args.input):
        print(f"âŒ é”™è¯¯: è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {args.input}")
        return
    
    if not args.input.endswith('.fvecs'):
        print(f"âŒ é”™è¯¯: è¾“å…¥æ–‡ä»¶å¿…é¡»æ˜¯ .fvecs æ ¼å¼")
        return
    
    # è·å–æ–‡ä»¶ä¿¡æ¯
    try:
        total_vectors, dimension = get_fvecs_info(args.input)
    except Exception as e:
        print(f"âŒ é”™è¯¯: æ— æ³•è¯»å–æ–‡ä»¶ä¿¡æ¯: {e}")
        return
    
    print(f"ğŸ“ æ–‡ä»¶ä¿¡æ¯:")
    print(f"  æ–‡ä»¶è·¯å¾„: {args.input}")
    print(f"  æ€»å‘é‡æ•°: {total_vectors:,}")
    print(f"  å‘é‡ç»´åº¦: {dimension}")
    print(f"  æ–‡ä»¶å¤§å°: {os.path.getsize(args.input) / (1024**3):.2f} GB")
    
    # å¦‚æœåªæ˜¾ç¤ºä¿¡æ¯ï¼Œç›´æ¥è¿”å›
    if args.info_only:
        return
    
    # å»ºè®®åˆ†å‰²å¤§å°
    if args.suggest_size:
        suggested_size = suggest_chunk_size(total_vectors, dimension, args.memory)
        memory_info = estimate_memory_usage(total_vectors, dimension, suggested_size)
        
        print(f"\nğŸ’¡ å†…å­˜åˆ†æ (é™åˆ¶: {args.memory} GB):")
        print(f"  å»ºè®®åˆ†å‰²å¤§å°: {suggested_size:,} å‘é‡")
        print(f"  å•å—å†…å­˜éœ€æ±‚: {memory_info['chunk_memory_gb']:.2f} GB")
        print(f"  æ€»å†…å­˜éœ€æ±‚: {memory_info['total_memory_gb']:.2f} GB")
        print(f"  é¢„è®¡åˆ†å‰²å—æ•°: {math.ceil(total_vectors / suggested_size)}")
        
        if not args.size:
            response = input(f"\næ˜¯å¦ä½¿ç”¨å»ºè®®çš„åˆ†å‰²å¤§å° {suggested_size:,}? (y/n): ")
            if response.lower() in ['y', 'yes']:
                args.size = suggested_size
            else:
                print("å·²å–æ¶ˆåˆ†å‰²æ“ä½œ")
                return
    
    # æ£€æŸ¥å¿…éœ€å‚æ•°
    if not args.size:
        print(f"âŒ é”™è¯¯: è¯·æŒ‡å®šåˆ†å‰²å¤§å° (-s) æˆ–ä½¿ç”¨ --suggest-size")
        return
    
    if not args.output:
        print(f"âŒ é”™è¯¯: è¯·æŒ‡å®šè¾“å‡ºç›®å½• (-o)")
        return
    
    # éªŒè¯åˆ†å‰²å¤§å°
    if args.size <= 0:
        print(f"âŒ é”™è¯¯: åˆ†å‰²å¤§å°å¿…é¡»å¤§äº 0")
        return
    
    if args.size > total_vectors:
        print(f"âš ï¸ è­¦å‘Š: åˆ†å‰²å¤§å° ({args.size:,}) å¤§äºæ€»å‘é‡æ•° ({total_vectors:,})")
        print(f"å°†ä½¿ç”¨æ€»å‘é‡æ•°ä½œä¸ºåˆ†å‰²å¤§å°")
        args.size = total_vectors
    
    # æ˜¾ç¤ºå†…å­˜ä¼°ç®—
    memory_info = estimate_memory_usage(total_vectors, dimension, args.size)
    print(f"\nğŸ’¾ å†…å­˜ä¼°ç®—:")
    print(f"  å•å—å†…å­˜éœ€æ±‚: {memory_info['chunk_memory_gb']:.2f} GB")
    print(f"  æ€»å†…å­˜éœ€æ±‚: {memory_info['total_memory_gb']:.2f} GB")
    
    if memory_info['total_memory_gb'] > args.memory:
        print(f"  âš ï¸ è­¦å‘Š: ä¼°ç®—å†…å­˜éœ€æ±‚è¶…è¿‡é™åˆ¶ ({args.memory} GB)")
        response = input("æ˜¯å¦ç»§ç»­? (y/n): ")
        if response.lower() not in ['y', 'yes']:
            print("å·²å–æ¶ˆåˆ†å‰²æ“ä½œ")
            return
    
    # æ‰§è¡Œåˆ†å‰²
    try:
        output_files = split_fvecs_file(
            args.input, 
            args.output, 
            args.size, 
            args.prefix, 
            args.start
        )
        
        print(f"\nğŸ‰ åˆ†å‰²æˆåŠŸå®Œæˆ!")
        print(f"ç”Ÿæˆäº† {len(output_files)} ä¸ªæ–‡ä»¶")
        
    except Exception as e:
        print(f"âŒ åˆ†å‰²è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        return


if __name__ == "__main__":
    main()