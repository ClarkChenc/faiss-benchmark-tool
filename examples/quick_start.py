#!/usr/bin/env python3
"""
FAISS Benchmark Framework - å¿«é€Ÿå¼€å§‹ç¤ºä¾‹

è¿™ä¸ªè„šæœ¬æ¼”ç¤ºäº†å¦‚ä½•å¿«é€Ÿå¼€å§‹ä½¿ç”¨ FAISS åŸºå‡†æµ‹è¯•æ¡†æ¶ã€‚
å®ƒåˆ›å»ºä¸€ä¸ªç®€å•çš„æ•°æ®é›†ï¼Œè¿è¡ŒåŸºæœ¬çš„åŸºå‡†æµ‹è¯•ï¼Œå¹¶ç”Ÿæˆç»“æœæŠ¥å‘Šã€‚
"""

import os
import sys
import numpy as np
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from faiss_benchmark import BenchmarkRunner
from faiss_benchmark.utils.logger import get_logger
from faiss_benchmark.utils.io_utils import write_fvecs, write_ivecs


def create_sample_dataset(output_dir="datasets", dataset_name="quick_start"):
    """åˆ›å»ºä¸€ä¸ªç®€å•çš„ç¤ºä¾‹æ•°æ®é›†"""
    print("ğŸ”§ åˆ›å»ºç¤ºä¾‹æ•°æ®é›†...")
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(output_dir, exist_ok=True)
    
    # æ•°æ®é›†å‚æ•°
    dimension = 128
    nb_base = 10000      # åŸºç¡€å‘é‡æ•°é‡
    nb_query = 100       # æŸ¥è¯¢å‘é‡æ•°é‡
    k = 10               # æ¯ä¸ªæŸ¥è¯¢çš„çœŸå®è¿‘é‚»æ•°é‡
    
    # ç”Ÿæˆéšæœºæ•°æ®
    np.random.seed(42)
    base_vectors = np.random.random((nb_base, dimension)).astype('float32')
    query_vectors = np.random.random((nb_query, dimension)).astype('float32')
    
    # è®¡ç®—çœŸå®çš„æœ€è¿‘é‚»ï¼ˆä½¿ç”¨æš´åŠ›æœç´¢ï¼‰
    print("  è®¡ç®—çœŸå®æœ€è¿‘é‚»...")
    distances = np.linalg.norm(
        query_vectors[:, np.newaxis, :] - base_vectors[np.newaxis, :, :], 
        axis=2
    )
    ground_truth = np.argsort(distances, axis=1)[:, :k].astype('int32')
    
    # ä¿å­˜æ•°æ®é›†æ–‡ä»¶
    base_file = os.path.join(output_dir, f"{dataset_name}_base.fvecs")
    query_file = os.path.join(output_dir, f"{dataset_name}_query.fvecs")
    gt_file = os.path.join(output_dir, f"{dataset_name}_groundtruth.ivecs")
    
    write_fvecs(base_file, base_vectors)
    write_fvecs(query_file, query_vectors)
    write_ivecs(gt_file, ground_truth)
    
    print(f"  âœ… æ•°æ®é›†å·²åˆ›å»º:")
    print(f"    åŸºç¡€å‘é‡: {base_file} ({nb_base} vectors, {dimension}D)")
    print(f"    æŸ¥è¯¢å‘é‡: {query_file} ({nb_query} vectors, {dimension}D)")
    print(f"    çœŸå®ç»“æœ: {gt_file} (top-{k} for each query)")
    
    return {
        "base_file": base_file,
        "query_file": query_file,
        "ground_truth_file": gt_file,
        "dimension": dimension,
        "nb_base": nb_base,
        "nb_query": nb_query
    }


def run_quick_benchmark():
    """è¿è¡Œå¿«é€ŸåŸºå‡†æµ‹è¯•"""
    print("\nğŸš€ å¼€å§‹å¿«é€ŸåŸºå‡†æµ‹è¯•...")
    
    # åˆ›å»ºç¤ºä¾‹æ•°æ®é›†
    dataset_info = create_sample_dataset()
    
    # åˆå§‹åŒ–åŸºå‡†æµ‹è¯•è¿è¡Œå™¨
    print("\nğŸ“Š åˆå§‹åŒ–åŸºå‡†æµ‹è¯•è¿è¡Œå™¨...")
    runner = BenchmarkRunner("config.yaml")
    
    # æ·»åŠ æ•°æ®é›†
    dataset_name = "quick_start"
    runner.dataset_manager.add_dataset(
        name=dataset_name,
        base_file=dataset_info["base_file"],
        query_file=dataset_info["query_file"],
        ground_truth_file=dataset_info["ground_truth_file"]
    )
    
    # å®šä¹‰è¦æµ‹è¯•çš„ç´¢å¼•é…ç½®
    index_configs = [
        {"type": "Flat", "params": {}},
        {"type": "IVFFlat", "params": {"nlist": 100, "nprobe": 10}},
        {"type": "IVFPQ", "params": {"nlist": 100, "m": 8, "nbits": 8, "nprobe": 10}},
    ]
    
    # è¿è¡ŒåŸºå‡†æµ‹è¯•
    results = []
    for i, index_config in enumerate(index_configs, 1):
        print(f"\nğŸ” è¿è¡Œæµ‹è¯• {i}/{len(index_configs)}: {index_config['type']}")
        
        try:
            # CPU æµ‹è¯•
            result_cpu = runner.run_single_benchmark(
                dataset_name=dataset_name,
                index_config=index_config,
                hardware_type="cpu",
                k=10
            )
            result_cpu['hardware_type'] = 'cpu'
            results.append(result_cpu)
            
            print(f"  CPU - QPS: {result_cpu['qps']:.1f}, "
                  f"Recall: {result_cpu['recall']:.3f}, "
                  f"æ„å»ºæ—¶é—´: {result_cpu['index_build_time']:.2f}s")
            
            # GPU æµ‹è¯•ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            try:
                result_gpu = runner.run_single_benchmark(
                    dataset_name=dataset_name,
                    index_config=index_config,
                    hardware_type="gpu",
                    k=10
                )
                result_gpu['hardware_type'] = 'gpu'
                results.append(result_gpu)
                
                print(f"  GPU - QPS: {result_gpu['qps']:.1f}, "
                      f"Recall: {result_gpu['recall']:.3f}, "
                      f"æ„å»ºæ—¶é—´: {result_gpu['index_build_time']:.2f}s")
                      
            except Exception as e:
                print(f"  GPU æµ‹è¯•è·³è¿‡: {e}")
                
        except Exception as e:
            print(f"  âŒ æµ‹è¯•å¤±è´¥: {e}")
    
    return results


def generate_quick_report(results):
    """ç”Ÿæˆå¿«é€ŸæŠ¥å‘Š"""
    print("\nğŸ“‹ ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š...")
    
    if not results:
        print("  âŒ æ²¡æœ‰å¯ç”¨çš„æµ‹è¯•ç»“æœ")
        return
    
    # åˆ›å»ºç»“æœç›®å½•
    os.makedirs("results", exist_ok=True)
    
    # æŒ‰æ€§èƒ½æŒ‡æ ‡æ’åº
    print("\nğŸ† æ€§èƒ½æ’è¡Œæ¦œ:")
    print("-" * 60)
    print(f"{'ç´¢å¼•ç±»å‹':<15} {'ç¡¬ä»¶':<6} {'QPS':<8} {'Recall':<8} {'æ„å»ºæ—¶é—´':<8}")
    print("-" * 60)
    
    # æŒ‰ QPS æ’åº
    sorted_results = sorted(results, key=lambda x: x['qps'], reverse=True)
    for result in sorted_results:
        print(f"{result['index_name']:<15} "
              f"{result['hardware_type']:<6} "
              f"{result['qps']:<8.1f} "
              f"{result['recall']:<8.3f} "
              f"{result['index_build_time']:<8.2f}")
    
    # æ‰¾å‡ºæœ€ä½³æ€§èƒ½è€…
    best_qps = max(results, key=lambda x: x['qps'])
    best_recall = max(results, key=lambda x: x['recall'])
    fastest_build = min(results, key=lambda x: x['index_build_time'])
    
    print(f"\nğŸ¯ æœ€ä½³æ€§èƒ½:")
    print(f"  æœ€é«˜ QPS: {best_qps['index_name']} ({best_qps['hardware_type']}) - {best_qps['qps']:.1f}")
    print(f"  æœ€é«˜ Recall: {best_recall['index_name']} ({best_recall['hardware_type']}) - {best_recall['recall']:.3f}")
    print(f"  æœ€å¿«æ„å»º: {fastest_build['index_name']} ({fastest_build['hardware_type']}) - {fastest_build['index_build_time']:.2f}s")
    
    # ä¿å­˜è¯¦ç»†ç»“æœ
    import json
    results_file = "results/quick_start_results.json"
    with open(results_file, 'w', encoding='utf-8') as f:
        json.dump(results, f, indent=2, ensure_ascii=False)
    
    print(f"\nğŸ’¾ è¯¦ç»†ç»“æœå·²ä¿å­˜åˆ°: {results_file}")


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ‰ æ¬¢è¿ä½¿ç”¨ FAISS Benchmark Framework!")
    print("è¿™æ˜¯ä¸€ä¸ªå¿«é€Ÿå¼€å§‹ç¤ºä¾‹ï¼Œå°†æ¼”ç¤ºåŸºæœ¬çš„åŸºå‡†æµ‹è¯•åŠŸèƒ½ã€‚")
    
    try:
        # è¿è¡Œå¿«é€ŸåŸºå‡†æµ‹è¯•
        results = run_quick_benchmark()
        
        # ç”ŸæˆæŠ¥å‘Š
        generate_quick_report(results)
        
        print("\nâœ… å¿«é€Ÿå¼€å§‹ç¤ºä¾‹å®Œæˆ!")
        print("\nğŸ“š æ¥ä¸‹æ¥ä½ å¯ä»¥:")
        print("  1. æŸ¥çœ‹ examples/basic_benchmark.py äº†è§£æ›´å¤šåŸºç¡€åŠŸèƒ½")
        print("  2. æŸ¥çœ‹ examples/advanced_benchmark.py äº†è§£é«˜çº§åŠŸèƒ½")
        print("  3. ä¿®æ”¹ config.yaml æ¥è‡ªå®šä¹‰é…ç½®")
        print("  4. ä½¿ç”¨ CLI å·¥å…·: python -m faiss_benchmark.cli --help")
        
    except Exception as e:
        print(f"\nâŒ è¿è¡Œè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()